{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RedeX\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torcheval import metrics\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext import vocab\n",
    "from torchtext.transforms import ToTensor\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from functools import partial\n",
    "import tweets_classifier_torch\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../Datasets/disaster_tweets\"\n",
    "LOGS_FOLDER = \"./logs\"\n",
    "CHECKPOINT_DIR = \"./tweets_classifier/checkpoints\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SHUFFLE_SEED = 42\n",
    "EPOCHS = 10\n",
    "BATCH = 32\n",
    "MAX_SENTENCE_LENGTH = 165\n",
    "EMBEDDING_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_run_logger(folder, model):\n",
    "    run_folder = f\"{folder}/{model.__class__.__name__}\"\n",
    "    try:\n",
    "        run_n = int(max(os.listdir(run_folder)))\n",
    "        run_n += 1\n",
    "    except:\n",
    "        run_n = 0\n",
    "    return SummaryWriter(f\"{run_folder}/{run_n}\")\n",
    "    \n",
    "def train_step(\n",
    "        model: tweets_classifier_torch.model.TweetsDisasterClassifier,\n",
    "        data: tweets_classifier_torch.datasets.TweetsV2,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        metrics_dict: Dict[str, metrics.Metric],\n",
    "        device: str):\n",
    "    model.to(device)\n",
    "    ov_loss = 0\n",
    "    for batch, (X, y) in enumerate(data):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model(X).squeeze()\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ov_loss += loss\n",
    "\n",
    "        for metric in metrics_dict.values():\n",
    "            metric.to(device)\n",
    "            metric.update(y_pred, y)\n",
    "\n",
    "    return ov_loss / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "train_data = tweets_classifier_torch.datasets.TweetsV2(\n",
    "    file = f\"{DATA_DIR}/train_preprocessed.parquet\",\n",
    "    transform = ToTensor(dtype = torch.float32),\n",
    "    target_transform = partial(torch.tensor, dtype = torch.float32),\n",
    "    concat_cols = True,\n",
    "    vectorize = True,\n",
    "    max_vector_length = MAX_SENTENCE_LENGTH \n",
    ")\n",
    "\n",
    "#num_workers = None - 1m52s\n",
    "#num_workers = 8 - too long \n",
    "#num_workers = 8, persistent_workers = True - 1m15s\n",
    "#num_workers = 12, persistent_workers = True - 1m25s\n",
    "#num_workers = 8, persistent_workers = True, prefetch_factor = 4 - 1m25s\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    num_workers = 8,\n",
    "    persistent_workers = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tweets_classifier_torch.model.TweetsDisasterClassifier(\n",
    "    sentence_length = MAX_SENTENCE_LENGTH,\n",
    "    vocab_size = pretrained_tokenizer.vocab_size,\n",
    "    embed_dim = EMBEDDING_SIZE,\n",
    "    ff_dim = 32,\n",
    "    num_attention_heads = 8).to(DEVICE)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "metrics_dict = {\"F1\": metrics.BinaryF1Score(), \"AUC\": metrics.BinaryAUROC()}\n",
    "optim = torch.optim.Adam(\n",
    "    params = model.parameters(),\n",
    "    lr = 1e-5,\n",
    "    betas = (0.9, 0.98),\n",
    "    eps = 1e-9\n",
    ")\n",
    "model_name = model.__class__.__name__\n",
    "writer = create_run_logger(LOGS_FOLDER, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = train_step(\n",
    "        model = model,\n",
    "        data = train_dataloader,\n",
    "        optimizer = optim,\n",
    "        loss_fn = loss_fn,\n",
    "        metrics_dict = metrics_dict,\n",
    "        device = DEVICE\n",
    "    )\n",
    "    print(f\"Epoch: {epoch};\", end = ' ')\n",
    "\n",
    "    # Compute metrics of epoch\n",
    "    for name, metric in metrics_dict.items():\n",
    "        # Compute metric\n",
    "        metric_value = metric.compute()\n",
    "        print(f\"{name}: {metric_value};\", end = ' ')\n",
    "        # Add metric to tensorboard\n",
    "        writer.add_scalar(f\"{model_name}_{name}\", metric_value, epoch)\n",
    "        metric.reset()\n",
    "    print(f\"Loss: {epoch_loss};\")\n",
    "    # Add loss to tensorboard\n",
    "    writer.add_scalar(f\"{model_name}_loss\", epoch_loss, epoch)\n",
    "    \n",
    "# torch.save(model.state_dict(), './tweets_classifier_torch/weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
