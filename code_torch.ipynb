{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torcheval import metrics\n",
    "from torchtext import vocab\n",
    "from torchtext.transforms import ToTensor\n",
    "import os\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from functools import partial\n",
    "import tweets_classifier_torch\n",
    "from tweets_classifier_torch.helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../Datasets/disaster_tweets\"\n",
    "LOGS_FOLDER = \"./logs\"\n",
    "CHECKPOINT_DIR = \"./tweets_classifier/checkpoints\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SHUFFLE_SEED = 42\n",
    "EPOCHS = 10\n",
    "BATCH = 32\n",
    "MAX_SENTENCE_LENGTH = 165\n",
    "EMBEDDING_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "train_data = tweets_classifier_torch.datasets.TweetsV2(\n",
    "    file = f\"{DATA_DIR}/train_preprocessed.parquet\",\n",
    "    transform = ToTensor(dtype = torch.float32),\n",
    "    target_transform = partial(torch.tensor, dtype = torch.float32),\n",
    "    concat_cols = True,\n",
    "    vectorize = True,\n",
    "    max_vector_length = MAX_SENTENCE_LENGTH \n",
    ")\n",
    "\n",
    "#num_workers = None - 1m52s\n",
    "#num_workers = 8 - too long \n",
    "#num_workers = 8, persistent_workers = True - 1m15s\n",
    "#num_workers = 12, persistent_workers = True - 1m25s\n",
    "#num_workers = 8, persistent_workers = True, prefetch_factor = 4 - 1m25s\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    num_workers = 8,\n",
    "    persistent_workers = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tweets_classifier_torch.model.TweetsDisasterClassifier(\n",
    "    sentence_length = MAX_SENTENCE_LENGTH,\n",
    "    vocab_size = pretrained_tokenizer.vocab_size,\n",
    "    embed_dim = EMBEDDING_SIZE,\n",
    "    ff_dim = 32,\n",
    "    num_attention_heads = 8).to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "metrics_dict = {\n",
    "    \"F1\": metrics.BinaryF1Score(),\n",
    "    \"AUC\": metrics.BinaryAUROC()\n",
    "}\n",
    "optim = torch.optim.Adam(\n",
    "    params = model.parameters(),\n",
    "    lr = 1e-5,\n",
    "    betas = (0.9, 0.98),\n",
    "    eps = 1e-9\n",
    ")\n",
    "\n",
    "model_name = model.__class__.__name__\n",
    "writer = create_run_logger(LOGS_FOLDER, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = train_step(\n",
    "        model = model,\n",
    "        data = train_dataloader,\n",
    "        optimizer = optim,\n",
    "        loss_fn = loss_fn,\n",
    "        metrics_dict = metrics_dict,\n",
    "        device = DEVICE\n",
    "    )\n",
    "    print(f\"Epoch: {epoch};\", end = ' ')\n",
    "\n",
    "    # Compute metrics of epoch\n",
    "    for name, metric in metrics_dict.items():\n",
    "        # Compute metric\n",
    "        metric_value = metric.compute()\n",
    "        print(f\"{name}: {metric_value};\", end = ' ')\n",
    "        # Add metric to tensorboard\n",
    "        writer.add_scalar(f\"{model_name}_{name}\", metric_value, epoch)\n",
    "        metric.reset()\n",
    "    print(f\"Loss: {epoch_loss};\")\n",
    "    # Add loss to tensorboard\n",
    "    writer.add_scalar(f\"{model_name}_loss\", epoch_loss, epoch)\n",
    "    \n",
    "# torch.save(model.state_dict(), './tweets_classifier_torch/weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
